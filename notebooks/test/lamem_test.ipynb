{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script_dir = '/lustre06/project/6067616/soroush1/vitalab-trianing-clean-code/notebooks'\n",
      "parent_dir = '/lustre06/project/6067616/soroush1/vitalab-trianing-clean-code'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "script_dir = os.path.dirname(os.getcwd())  # Get the directory where the script is located\n",
    "parent_dir = os.path.dirname(script_dir)  # Get the parent directory\n",
    "\n",
    "print(f\"{script_dir = }\")\n",
    "print(f\"{parent_dir = }\")\n",
    "\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import PIL.Image\n",
    "\n",
    "from datasets.LaMem import LaMem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transform(resize:int = 256, desired_image_size:int = 224):\n",
    "    return transforms.Compose(\n",
    "                    [\n",
    "                        transforms.Resize((resize, resize), PIL.Image.BILINEAR),\n",
    "                        lambda x: np.array(x),\n",
    "                        lambda x: np.subtract(\n",
    "                            x[:, :, [2, 1, 0]], self.mean\n",
    "                        ),  # Subtract average mean from image (opposite order channels)\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.RandomHorizontalFlip(),\n",
    "                        transforms.RandomVerticalFlip(),\n",
    "                        transforms.RandomRotation(degrees=13),\n",
    "                        transforms.CenterCrop(\n",
    "                            desired_image_size\n",
    "                        ),  # Center crop to 224x224\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "\n",
    "def get_val_transform(resize:int = 256, desired_image_size:int = 224):\n",
    "    return transforms.Compose(\n",
    "                [\n",
    "                    transforms.Resize((resize, resize), PIL.Image.BILINEAR),\n",
    "                    lambda x: np.array(x),\n",
    "                    lambda x: np.subtract(\n",
    "                        x[:, :, [2, 1, 0]], self.mean\n",
    "                    ),  # Subtract average mean from image (opposite order channels)\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.CenterCrop(\n",
    "                        desired_image_size\n",
    "                    ),  # Center crop to 224x224\n",
    "                ]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of train dataset: 45000\n",
      "Len of val dataset: 3741\n",
      "Len of test dataset: 10000\n",
      "summation will be 58741\n"
     ]
    }
   ],
   "source": [
    "root = \"/home/soroush1/projects/def-kohitij/soroush1/pretrain-imagenet/data/lamem/lamem_images/lamem\"\n",
    "\n",
    "splits_list = os.listdir(os.path.join(root, \"splits\"))\n",
    "train_splits = list(sorted(filter(lambda x: \"train\" in x, splits_list)))\n",
    "val_splits = list(sorted(filter(lambda x: \"val\" in x, splits_list)))\n",
    "test_splits = list(sorted(filter(lambda x: \"test\" in x, splits_list)))\n",
    "\n",
    "train_splits = [train_splits[0]]\n",
    "val_splits = [val_splits[0]]\n",
    "test_splits = [test_splits[0]]\n",
    "\n",
    "\n",
    "change_labels = False\n",
    "\n",
    "train_dataset = LaMem(\n",
    "            root=root,\n",
    "            splits=train_splits,\n",
    "            transforms=get_train_transform(),\n",
    "            change_labels=change_labels,\n",
    "        )\n",
    "\n",
    "print(f\"Len of train dataset: {len(train_dataset)}\")\n",
    "\n",
    "\n",
    "val_dataset = LaMem(\n",
    "            root=root,\n",
    "            splits=val_splits,\n",
    "            transforms=get_val_transform(),\n",
    "            change_labels=change_labels,\n",
    "        )\n",
    "\n",
    "print(f\"Len of val dataset: {len(val_dataset)}\")\n",
    "test_dataset = LaMem(\n",
    "            root=root,\n",
    "            splits=test_splits,\n",
    "            transforms=get_val_transform(),\n",
    "            change_labels=change_labels,\n",
    "        )\n",
    "\n",
    "print(f\"Len of test dataset: {len(test_dataset)}\")\n",
    "\n",
    "print(f\"summation will be {len(test_dataset) + len(val_dataset) + len(train_dataset)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
